{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aeee7e44",
      "metadata": {},
      "source": [
        "# Convolution and Matrix Multiplication\n",
        "\n",
        "The [convolution](https://en.wikipedia.org/wiki/Kernel_(image_processing)) is a well known image transformation used to transform an image. It can be used to blur, to compute the gradient in one direction and it is widely used in deep neural networks. Having a fast implementation is important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3bb4f0a5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "15fdc3ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c21bc5ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext mlprodict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa367092",
      "metadata": {},
      "source": [
        "## numpy\n",
        "\n",
        "Image have often 4 dimensions (N, C, H, W) = (batch, channels, height, width). Let's first start with a 2D image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "73efa320",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 7)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "shape = (5, 7)\n",
        "N = numpy.prod(shape)\n",
        "data = numpy.arange(N).astype(numpy.float32).reshape(shape)\n",
        "# data[:, :] = 0\n",
        "# data[2, 3] = 1\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ae57cd",
      "metadata": {},
      "source": [
        "Let's a 2D kernel, the same one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "26eb8bbe",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.],\n",
              "       [7., 8., 9.]], dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kernel = (numpy.arange(9) + 1).reshape(3, 3).astype(numpy.float32)\n",
        "kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0997ee66",
      "metadata": {},
      "source": [
        "### raw convolution\n",
        "\n",
        "A raw version of a 2D convolution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6c7bf5e1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 7)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def raw_convolution(data, kernel):\n",
        "    rx = (kernel.shape[0] - 1) // 2\n",
        "    ry = (kernel.shape[1] - 1) // 2\n",
        "    res = numpy.zeros(data.shape, dtype=data.dtype)\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            for x in range(kernel.shape[0]):\n",
        "                for y in range(kernel.shape[1]):\n",
        "                    a = i + x - rx\n",
        "                    b = j + y - ry\n",
        "                    if a < 0 or b < 0 or a >= data.shape[0] or b >= data.shape[1]:\n",
        "                        continue\n",
        "                    res[i, j] += kernel[x, y] * data[a, b]\n",
        "    return res\n",
        "\n",
        "res = raw_convolution(data, kernel)\n",
        "res.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8d5d5ea8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 134.,  211.,  250.,  289.,  328.,  367.,  238.],\n",
              "       [ 333.,  492.,  537.,  582.,  627.,  672.,  423.],\n",
              "       [ 564.,  807.,  852.,  897.,  942.,  987.,  612.],\n",
              "       [ 795., 1122., 1167., 1212., 1257., 1302.,  801.],\n",
              "       [ 422.,  571.,  592.,  613.,  634.,  655.,  382.]], dtype=float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ae0942",
      "metadata": {},
      "source": [
        "### With pytorch\n",
        "\n",
        "*pytorch* is optimized for deep learning and prefers 4D tenors to represent multiple images. We add two empty dimension to the previous example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "38bbba0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import from_numpy\n",
        "from torch.nn.functional import conv2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "48afd3c7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 5, 7])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rest = conv2d(from_numpy(data[numpy.newaxis, numpy.newaxis, ...]), \n",
        "              from_numpy(kernel[numpy.newaxis, numpy.newaxis, ...]),\n",
        "              padding=(1, 1))\n",
        "rest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1918ef44",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 134.,  211.,  250.,  289.,  328.,  367.,  238.],\n",
              "          [ 333.,  492.,  537.,  582.,  627.,  672.,  423.],\n",
              "          [ 564.,  807.,  852.,  897.,  942.,  987.,  612.],\n",
              "          [ 795., 1122., 1167., 1212., 1257., 1302.,  801.],\n",
              "          [ 422.,  571.,  592.,  613.,  634.,  655.,  382.]]]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0996bcc",
      "metadata": {},
      "source": [
        "Everything works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8be181a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy.testing import assert_almost_equal\n",
        "assert_almost_equal(res, rest[0, 0].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a095260",
      "metadata": {},
      "source": [
        "### using Gemm?\n",
        "\n",
        "A fast implementation could reuse whatever exists with a fast implementation such as a matrix multiplication. The goal is to transform the tensor `data` into a new matrix which can be mutiplied with a flatten kernel and finally reshaped into the expected result. pytorch calls this function [Unfold](https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html). This function is also called [im2col](https://caffe.berkeleyvision.org/tutorial/layers/im2col.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f46791f5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 35])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn import Unfold\n",
        "unfold = Unfold(kernel_size=(3, 3), padding=(1, 1))(from_numpy(data[numpy.newaxis, numpy.newaxis, ...]))\n",
        "unfold.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50aef0a",
      "metadata": {},
      "source": [
        "We then multiply this matrix with the flattened kernel and reshape it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2acce304",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 7)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "impl = kernel.flatten() @ unfold.numpy()\n",
        "impl = impl.reshape(data.shape)\n",
        "impl.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "32b8ead6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 134.,  211.,  250.,  289.,  328.,  367.,  238.],\n",
              "       [ 333.,  492.,  537.,  582.,  627.,  672.,  423.],\n",
              "       [ 564.,  807.,  852.,  897.,  942.,  987.,  612.],\n",
              "       [ 795., 1122., 1167., 1212., 1257., 1302.,  801.],\n",
              "       [ 422.,  571.,  592.,  613.,  634.,  655.,  382.]], dtype=float32)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "impl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd11c282",
      "metadata": {},
      "source": [
        "Everything works as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bb016ae0",
      "metadata": {},
      "outputs": [],
      "source": [
        "assert_almost_equal(res, impl)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bfd881b",
      "metadata": {},
      "source": [
        "## What is ConvTranspose?\n",
        "\n",
        "Deep neural network are trained with a stochastic gradient descent. The gradient of every layer needs to be computed including the gradient of a convolution transpose. That seems easier with the second expression of a convolution relying on a matrix multiplication and function `im2col`. `im2col` is just a new matrix built from `data` where every value was copied in 9=3x3 locations. The gradient against an input value `data[i,j]` is the sum of 9=3x3 values from the output gradient. If `im2col` plays with indices, the gradient requires to do the same thing in the other way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "632e0cd8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 134.,  211.,  250.,  289.,  328.,  367.,  238.],\n",
              "       [ 333.,  492.,  537.,  582.,  627.,  672.,  423.],\n",
              "       [ 564.,  807.,  852.,  897.,  942.,  987.,  612.],\n",
              "       [ 795., 1122., 1167., 1212., 1257., 1302.,  801.],\n",
              "       [ 422.,  571.,  592.,  613.,  634.,  655.,  382.]], dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# impl[:, :] = 0\n",
        "# impl[2, 3] = 1\n",
        "impl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "22fd7b7b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[ 2672.,  5379.,  6804.,  7659.,  8514.,  8403.,  6254.],\n",
              "         [ 8117., 15408., 18909., 20790., 22671., 21780., 15539.],\n",
              "         [14868., 27315., 32400., 34425., 36450., 34191., 23922.],\n",
              "         [20039., 35544., 41283., 43164., 45045., 41508., 28325.],\n",
              "         [18608., 32055., 36756., 38151., 39546., 35943., 23966.]]]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn.functional import conv_transpose2d\n",
        "\n",
        "ct = conv_transpose2d(from_numpy(impl.reshape(data.shape)[numpy.newaxis, numpy.newaxis, ...]),\n",
        "                      from_numpy(kernel[numpy.newaxis, numpy.newaxis, ...]),\n",
        "                      padding=(1, 1)).numpy()\n",
        "ct"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53aab3cf",
      "metadata": {},
      "source": [
        "And now the version with `col2im` or [Fold](https://pytorch.org/docs/stable/generated/torch.nn.Fold.html#torch.nn.Fold) applied on the result product of the output from `Conv` and the kernel: the output of `Conv` is multiplied by every coefficient of the kernel. Then all these matrices are concatenated to build a matrix of the same shape of `unfold`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "05269f31",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 35)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = kernel.flatten().reshape((-1, 1)) @ impl.flatten().reshape((1, -1))\n",
        "p.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "685ce888",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 5, 7])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn import Fold\n",
        "\n",
        "fold = Fold(kernel_size=(3, 3), output_size=(5, 7), padding=(1, 1))(from_numpy(p[numpy.newaxis, ...]))\n",
        "fold.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3e609aa2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 2672.,  5379.,  6804.,  7659.,  8514.,  8403.,  6254.],\n",
              "          [ 8117., 15408., 18909., 20790., 22671., 21780., 15539.],\n",
              "          [14868., 27315., 32400., 34425., 36450., 34191., 23922.],\n",
              "          [20039., 35544., 41283., 43164., 45045., 41508., 28325.],\n",
              "          [18608., 32055., 36756., 38151., 39546., 35943., 23966.]]]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101b50ba",
      "metadata": {},
      "source": [
        "## onnxruntime-training\n",
        "\n",
        "Following lines shows how *onnxruntime* handles the gradient computation. This section still needs work."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf4c3ada",
      "metadata": {},
      "source": [
        "### Conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8fb68ccd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"Maf4d328ff92d469eb336d9107242d2a9-cont\"><div id=\"Maf4d328ff92d469eb336d9107242d2a9\" style=\"width:;height:;\"></div></div>\n",
              "<script>\n",
              "\n",
              "require(['http://www.xavierdupre.fr/js/vizjs/viz.js'], function() { var svgGraph = Viz(\"digraph{\\n  ranksep=0.25;\\n  orientation=portrait;\\n  nodesep=0.05;\\n  size=7;\\n\\n  X [shape=box color=red label=\\\"X\\nfloat(('?',))\\\" fontsize=10];\\n\\n  out_con_0 [shape=box color=green label=\\\"out_con_0\\nfloat(('?',))\\\" fontsize=10];\\n\\n  init [shape=box label=\\\"init\\nfloat32((1, 1, 3, 3))\\n[[[[1. 2. 3.]\\n   [4. 5. 6.]\\n   [7. 8. 9.]]]]\\\" fontsize=10];\\n\\n  _conv [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Conv\\n(_conv)\\npads=[1 1 1 1]\\\" fontsize=10];\\n  X -> _conv;\\n  init -> _conv;\\n  _conv -> out_con_0;\\n}\");\n",
              "document.getElementById('Maf4d328ff92d469eb336d9107242d2a9').innerHTML = svgGraph; });\n",
              "\n",
              "</script>"
            ],
            "text/plain": [
              "<jyquickhelper.jspy.render_nb_js_dot.RenderJsDot at 0x11e73e29250>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mlprodict.npy.xop import loadop\n",
        "OnnxConv = loadop('Conv')\n",
        "node = OnnxConv('X', kernel[numpy.newaxis, numpy.newaxis, ...], pads=[1, 1, 1, 1])\n",
        "onx = node.to_onnx(numpy.float32, numpy.float32)\n",
        "%onnxview onx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2d34f521",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[ 134.,  211.,  250.,  289.,  328.,  367.,  238.],\n",
              "         [ 333.,  492.,  537.,  582.,  627.,  672.,  423.],\n",
              "         [ 564.,  807.,  852.,  897.,  942.,  987.,  612.],\n",
              "         [ 795., 1122., 1167., 1212., 1257., 1302.,  801.],\n",
              "         [ 422.,  571.,  592.,  613.,  634.,  655.,  382.]]]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mlprodict.onnxrt import OnnxInference\n",
        "oinf = OnnxInference(onx, runtime='onnxruntime1')\n",
        "oinf.run({'X': data[numpy.newaxis, numpy.newaxis, ...]})['out_con_0']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0098eb16",
      "metadata": {},
      "source": [
        "It is the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "66a592f5",
      "metadata": {
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from onnxcustom.training.grad_helper import onnx_derivative, DerivativeOptions\n",
        "grad = onnx_derivative(onx, options=DerivativeOptions.FillGrad | DerivativeOptions.KeepOutputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2b042ac4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"M97b43bf939a446ef8a4bea97df55b057-cont\"><div id=\"M97b43bf939a446ef8a4bea97df55b057\" style=\"width:;height:;\"></div></div>\n",
              "<script>\n",
              "\n",
              "require(['http://www.xavierdupre.fr/js/vizjs/viz.js'], function() { var svgGraph = Viz(\"digraph{\\n  ranksep=0.25;\\n  orientation=portrait;\\n  nodesep=0.05;\\n  size=7;\\n\\n  X [shape=box color=red label=\\\"X\\nfloat(('?',))\\\" fontsize=10];\\n  init [shape=box color=red label=\\\"init\\nfloat((1, 1, 3, 3))\\\" fontsize=10];\\n\\n  X_grad [shape=box color=green label=\\\"X_grad\\nfloat(('?',))\\\" fontsize=10];\\n  init_grad [shape=box color=green label=\\\"init_grad\\nfloat((1, 1, 3, 3))\\\" fontsize=10];\\n  out_con_0 [shape=box color=green label=\\\"out_con_0\\nfloat(('?',))\\\" fontsize=10];\\n\\n\\n  _conv [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Conv\\n(_conv)\\nauto_pad=b'NOTSET'\\ngroup=1\\npads=[1 1 1 1]\\\" fontsize=10];\\n  X -> _conv;\\n  init -> _conv;\\n  _conv -> out_con_0;\\n\\n  _conv_Grad_ConvGrad_0 [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"ConvGrad\\n(_conv_Grad_ConvGrad_0)\\nauto_pad=b'NOTSET'\\ngroup=1\\npads=[1 1 1 1]\\\" fontsize=10];\\n  out_con_0_grad -> _conv_Grad_ConvGrad_0;\\n  X -> _conv_Grad_ConvGrad_0;\\n  init -> _conv_Grad_ConvGrad_0;\\n  _conv_Grad_ConvGrad_0 -> X_grad;\\n  _conv_Grad_ConvGrad_0 -> init_grad;\\n\\n  out_con_0_shape [shape=box label=\\\"out_con_0_shape\\\" fontsize=10];\\n  Shape [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Shape\\n(Shape)\\\" fontsize=10];\\n  out_con_0 -> Shape;\\n  Shape -> out_con_0_shape;\\n\\n  out_con_0_grad [shape=box label=\\\"out_con_0_grad\\\" fontsize=10];\\n  ConstantOfShape [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"ConstantOfShape\\n(ConstantOfShape)\\nvalue=[1.]\\\" fontsize=10];\\n  out_con_0_shape -> ConstantOfShape;\\n  ConstantOfShape -> out_con_0_grad;\\n}\");\n",
              "document.getElementById('M97b43bf939a446ef8a4bea97df55b057').innerHTML = svgGraph; });\n",
              "\n",
              "</script>"
            ],
            "text/plain": [
              "<jyquickhelper.jspy.render_nb_js_dot.RenderJsDot at 0x11e73bf1bb0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%onnxview grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "372eb667",
      "metadata": {},
      "outputs": [],
      "source": [
        "oinf = OnnxInference(grad, runtime='onnxruntime1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6d416375",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'X_grad': array([[[[12., 21., 21., 21., 21., 21., 16.],\n",
              "          [27., 45., 45., 45., 45., 45., 33.],\n",
              "          [27., 45., 45., 45., 45., 45., 33.],\n",
              "          [27., 45., 45., 45., 45., 45., 33.],\n",
              "          [24., 39., 39., 39., 39., 39., 28.]]]], dtype=float32),\n",
              " 'init_grad': array([[[[312., 378., 336.],\n",
              "          [495., 595., 525.],\n",
              "          [480., 574., 504.]]]], dtype=float32),\n",
              " 'out_con_0': array([[[[ 134.,  211.,  250.,  289.,  328.,  367.,  238.],\n",
              "          [ 333.,  492.,  537.,  582.,  627.,  672.,  423.],\n",
              "          [ 564.,  807.,  852.,  897.,  942.,  987.,  612.],\n",
              "          [ 795., 1122., 1167., 1212., 1257., 1302.,  801.],\n",
              "          [ 422.,  571.,  592.,  613.,  634.,  655.,  382.]]]],\n",
              "       dtype=float32)}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oinf.run({'X': data[numpy.newaxis, numpy.newaxis, ...],\n",
        "          'init': kernel[numpy.newaxis, numpy.newaxis, ...]})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfc7478f",
      "metadata": {},
      "source": [
        "### ConvTranspose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9f1dedf0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"Mf31b7b035f334bd89b08e6aa52583729-cont\"><div id=\"Mf31b7b035f334bd89b08e6aa52583729\" style=\"width:;height:;\"></div></div>\n",
              "<script>\n",
              "\n",
              "require(['http://www.xavierdupre.fr/js/vizjs/viz.js'], function() { var svgGraph = Viz(\"digraph{\\n  ranksep=0.25;\\n  orientation=portrait;\\n  nodesep=0.05;\\n  size=7;\\n\\n  X [shape=box color=red label=\\\"X\\nfloat(('?',))\\\" fontsize=10];\\n\\n  out_con_0 [shape=box color=green label=\\\"out_con_0\\nfloat(('?',))\\\" fontsize=10];\\n\\n  init [shape=box label=\\\"init\\nfloat32((1, 1, 3, 3))\\n[[[[1. 2. 3.]\\n   [4. 5. 6.]\\n   [7. 8. 9.]]]]\\\" fontsize=10];\\n\\n  _convtranspose [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"ConvTranspose\\n(_convtranspose)\\npads=[1 1 1 1]\\\" fontsize=10];\\n  X -> _convtranspose;\\n  init -> _convtranspose;\\n  _convtranspose -> out_con_0;\\n}\");\n",
              "document.getElementById('Mf31b7b035f334bd89b08e6aa52583729').innerHTML = svgGraph; });\n",
              "\n",
              "</script>"
            ],
            "text/plain": [
              "<jyquickhelper.jspy.render_nb_js_dot.RenderJsDot at 0x11e73bf19d0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mlprodict.npy.xop import loadop\n",
        "\n",
        "OnnxConv = loadop('ConvTranspose')\n",
        "node = OnnxConv('X', kernel[numpy.newaxis, numpy.newaxis, ...], pads=[1, 1, 1, 1])\n",
        "onx = node.to_onnx(numpy.float32, numpy.float32)\n",
        "%onnxview onx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3b069a8e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[ 2672.,  5379.,  6804.,  7659.,  8514.,  8403.,  6254.],\n",
              "         [ 8117., 15408., 18909., 20790., 22671., 21780., 15539.],\n",
              "         [14868., 27315., 32400., 34425., 36450., 34191., 23922.],\n",
              "         [20039., 35544., 41283., 43164., 45045., 41508., 28325.],\n",
              "         [18608., 32055., 36756., 38151., 39546., 35943., 23966.]]]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oinf = OnnxInference(onx, runtime='onnxruntime1')\n",
        "oinf.run({'X': impl[numpy.newaxis, numpy.newaxis, ...]})['out_con_0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d488107c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c6ea6efc",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}